{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uW23e_zzHS94",
    "outputId": "51350079-df0e-44b5-a3ea-4e27acc81745"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Lambda, Dropout, MaxPool2D, concatenate\n",
    "from keras.layers import Conv2DTranspose, Concatenate, multiply, MaxPooling2D, UpSampling2D\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import MeanIoU\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import csv\n",
    "import sys\n",
    "import cv2\n",
    "import shapely.wkt\n",
    "import shapely.affinity\n",
    "from skimage.segmentation import find_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RWbfaVJXHS_c"
   },
   "outputs": [],
   "source": [
    "Patch_size, N_split, Class_Type = 224, 15, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22wLSPWqHTAi"
   },
   "outputs": [],
   "source": [
    "processed_data_dir = \"preprocessed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmztNSB7HTBl"
   },
   "outputs": [],
   "source": [
    "data_path = '..'\n",
    "w0 = 10\n",
    "sigma = 5\n",
    "N_split = 15\n",
    "Patch_size = 224\n",
    "class_type = 1\n",
    "class_dict = {class_type:0}\n",
    "grid_sizes_df = pd.read_csv(os.path.join(data_path, 'grid_sizes.csv'))\n",
    "grid_sizes_df = grid_sizes_df.rename(columns = {grid_sizes_df.columns[0]: 'IM_ID'})\n",
    "polygons_df = pd.read_csv(os.path.join(data_path, 'train_wkt_v4.csv'))\n",
    "show_mask = lambda mask: tiff.imshow(255*np.stack([mask, mask, mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ema8_ipKHTCV"
   },
   "outputs": [],
   "source": [
    "def getGridSize(img_id):\n",
    "        return tuple(grid_sizes_df[grid_sizes_df['IM_ID'] == img_id][['Xmax' ,'Ymin']].values[0])\n",
    "    \n",
    "def getPolygons(img_id):\n",
    "    poly_dict = dict()\n",
    "    img_poly_df = polygons_df[polygons_df['ImageId'] == img_id]\n",
    "    classes = img_poly_df['ClassType'].unique()\n",
    "    for class_type in classes:\n",
    "        poly_dict[int(class_type)] = shapely.wkt.loads(img_poly_df[img_poly_df['ClassType'] == class_type]['MultipolygonWKT'].values[0])\n",
    "    return poly_dict\n",
    "\n",
    "def getImage(img_id, img_band):\n",
    "\n",
    "    if img_band =='RGB':\n",
    "        file = os.path.join(data_path,'three_band', '{}.tif'.format(img_id))\n",
    "    else:\n",
    "        file = os.path.join(data_path,'sixteen_band', '{}_{}.tif'.format(img_id, img_band))    \n",
    "    img = tiff.imread(file)\n",
    "    img = img[:,:,None] if img_band == 'P' else np.rollaxis(img, 0, 3)\n",
    "    img = img.astype(np.float32)/16384 if img_band == 'A' else img.astype(np.float32)/2048\n",
    "    return img\n",
    "\n",
    "def getImageAllband(img_id, Scale_Size = None):\n",
    "    if not Scale_Size:\n",
    "        Scale_Size = Patch_size * N_split\n",
    "    img_RGB = cv2.resize(getImage(img_id, 'RGB'), (Scale_Size, Scale_Size))    \n",
    "    img_M = cv2.resize(getImage(img_id, 'M'), (Scale_Size, Scale_Size))\n",
    "    img_A = cv2.resize(getImage(img_id, 'A'), (Scale_Size, Scale_Size))\n",
    "    img_P = cv2.resize(getImage(img_id, 'P'),( Scale_Size, Scale_Size))\n",
    "    img = np.concatenate((img_RGB,img_M, img_A,img_P[:,:,None]), axis=2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Il8Q37CHTC4"
   },
   "outputs": [],
   "source": [
    "def getMask(img_id, img_shape):\n",
    "    polygons_vals_all_classes = getPolygons(img_id)\n",
    "    Xmax, Ymin = getGridSize(img_id)\n",
    "    H, W = img_shape\n",
    "    xfact = W * (W / (W + 1)) / Xmax\n",
    "    yfact = H * (H / (H + 1)) / Ymin\n",
    "    total_classes = len(class_dict)\n",
    "    masks = np.zeros((H, W, total_classes), dtype=np.uint8)\n",
    "    for class_type, polygons_vals in polygons_vals_all_classes.items():\n",
    "        if class_type in class_dict:\n",
    "            class_mask = np.zeros((H, W), dtype=np.uint8)\n",
    "            polygon_img = shapely.affinity.scale(polygons_vals, xfact = xfact, yfact = yfact, origin = (0, 0, 0))\n",
    "            if not polygon_img:\n",
    "                continue\n",
    "            external_region = []\n",
    "            internal_region = []\n",
    "            for poly_val in polygon_img:\n",
    "                external_region.append(np.array(poly_val.exterior.coords).round().astype(np.int32))\n",
    "                for poly_int in poly_val.interiors:\n",
    "                    internal_region.append(np.array(poly_int.coords).round().astype(np.int32))\n",
    "            cv2.fillPoly(class_mask, external_region, 1)\n",
    "            cv2.fillPoly(class_mask, internal_region, 0)\n",
    "            masks[:, :, class_dict[class_type]] = class_mask\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zyqXDZGpHTDY"
   },
   "outputs": [],
   "source": [
    "def getWeightMap(masks):\n",
    "    nrows, ncols = masks.shape[1:]\n",
    "    #masks = (masks > 0).astype(int)\n",
    "    dist_mat = np.zeros((nrows * ncols, masks.shape[0]))\n",
    "    X1, Y1 = np.meshgrid(np.arange(nrows), np.arange(ncols))\n",
    "    X1, Y1 = np.c_[X1.ravel(), Y1.ravel()].T\n",
    "    for i, mask in enumerate(masks):\n",
    "\n",
    "        X2, Y2 = np.nonzero(find_boundaries(mask, mode='inner'))\n",
    "        sum_x = (X2.reshape(-1, 1) - X1.reshape(1, -1)) ** 2\n",
    "        sum_y = (Y2.reshape(-1, 1) - Y1.reshape(1, -1)) ** 2\n",
    "        if len(sum_x) > 0 and len(sum_y) > 0:\n",
    "            dist_mat[:, i] = np.sqrt(sum_x + sum_y).min(axis=0)\n",
    "    ix = np.arange(dist_mat.shape[0])\n",
    "    if dist_mat.shape[1] == 1:\n",
    "        d1 = dist_mat.ravel()\n",
    "        border_loss_map = w0 * np.exp((-1 * (d1) ** 2) / (2 * (sigma ** 2)))\n",
    "    else:\n",
    "        if dist_mat.shape[1] == 2:\n",
    "            d1_ix, d2_ix = np.argpartition(dist_mat, 1, axis=1)[:, :2].T\n",
    "        else:\n",
    "            d1_ix, d2_ix = np.argpartition(dist_mat, 2, axis=1)[:, :2].T\n",
    "        d1 = dist_mat[ix, d1_ix]\n",
    "        d2 = dist_mat[ix, d2_ix]\n",
    "        border_loss_map = w0 * np.exp((-1 * (d1 + d2) ** 2) / (2 * (sigma ** 2)))\n",
    "    xBLoss = np.zeros((nrows, ncols))\n",
    "    xBLoss[X1, Y1] = border_loss_map\n",
    "    loss = np.zeros((nrows, ncols))\n",
    "    w_1 = 1 - masks.sum() / loss.size\n",
    "    w_0 = 1 - w_1\n",
    "    loss[masks.sum(0) == 1] = w_1\n",
    "    loss[masks.sum(0) == 0] = w_0\n",
    "    ZZ = xBLoss + loss\n",
    "    return ZZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4cDWVH6THTD2"
   },
   "outputs": [],
   "source": [
    "def normalizedImages(patch_img_batch):\n",
    "        return (patch_img_batch - np.mean(patch_img_batch))/np.std(patch_img_batch)\n",
    "    \n",
    "def getPatch(img_id):\n",
    "    N_patch = N_split**2\n",
    "    patch_all = []\n",
    "    img = getImageAllband(img_id)\n",
    "    masks = getMask(img_id, (img.shape[0], img.shape[1]))\n",
    "    for i in range(N_split):\n",
    "        for j in range(N_split):\n",
    "            y = masks[Patch_size*i:Patch_size*(i + 1), Patch_size*j:Patch_size*(j + 1)]\n",
    "            weight_map_y = []\n",
    "            for mask in y.transpose(2,0,1):\n",
    "                weight_map_y.append(getWeightMap(np.array([mask])))\n",
    "            weight_map_y = np.array(weight_map_y).transpose(1, 2, 0)#getWeightMap(y.transpose(2,0,1))\n",
    "            if np.sum(y) > 0:\n",
    "                x = img[Patch_size*i:Patch_size*(i + 1), Patch_size*j:Patch_size*(j + 1),:]\n",
    "                x = normalizedImages(x)\n",
    "                patch_all.append(np.concatenate((x, y, weight_map_y), axis = 2))\n",
    "    patch_all = np.asarray(patch_all)\n",
    "    return patch_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5AIz0RMGHTEJ"
   },
   "outputs": [],
   "source": [
    "def saveAllPatches(test_split = 0.2):\n",
    "    count = 0\n",
    "    x = []\n",
    "    img_ids = sorted(grid_sizes_df.IM_ID.unique())\n",
    "    for i, img_id in enumerate(img_ids):\n",
    "        print(\"Saving for image {}\".format(img_id))\n",
    "        x_all = getPatch(img_id)\n",
    "        if len(x_all) > 0:\n",
    "            count = count + 1\n",
    "            if count == 1:\n",
    "                x = x_all\n",
    "            else:\n",
    "                x = np.concatenate((x, x_all), axis = 0)\n",
    "    try:\n",
    "        trn = 1 - test_split\n",
    "        l = len(x)\n",
    "        train_stump = int(l * trn)\n",
    "        np.save(processed_data_dir + '/data_pos_%d_%d_train_class%d' % (Patch_size, N_split, class_type), x[:train_stump])\n",
    "        np.save(processed_data_dir + '/data_pos_%d_%d_test_class%d' % (Patch_size, N_split, class_type), x[train_stump:])\n",
    "        return None\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AWhw3zAvHTEb",
    "outputId": "bb809196-8605-43a5-ac2b-1bf29e2f7327"
   },
   "outputs": [],
   "source": [
    "#x = saveAllPatches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "fwNflXR_HTE-",
    "outputId": "fdae107a-fe0c-4a50-b33a-a3f1d3564f2f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jyXJ7UToHTFc"
   },
   "outputs": [],
   "source": [
    "def getModel(input_shape,\n",
    "             n_classes,\n",
    "             epsilon,\n",
    "             filter_seq = [32, 64, 128, 256, 512],\n",
    "             dropout_seq = [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "             kernel_size = 3,\n",
    "             activation = 'relu',\n",
    "             padding = 'same',\n",
    "             kernel_initializer = 'he_normal'):\n",
    "\n",
    "    assert len(filter_seq) > 0\n",
    "    assert len(filter_seq) >= len(dropout_seq)\n",
    "    if len(filter_seq) > len(dropout_seq):\n",
    "        pad = len(filter_seq) - len(dropout_seq)\n",
    "        pad_arr = [None]*pad\n",
    "        dropout_seq += pad_arr\n",
    "\n",
    "    def encoderBlock(inp, \n",
    "                     filters,\n",
    "                     kernel_size,\n",
    "                     block_num,\n",
    "                     strides = 1,\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same',\n",
    "                     kernel_initializer = 'he_normal',\n",
    "                     dropout_rate = None):\n",
    "\n",
    "        conv = Conv2D(filters,\n",
    "                      kernel_size,\n",
    "                      strides = strides,\n",
    "                      activation = activation,\n",
    "                      padding = padding,\n",
    "                      kernel_initializer = kernel_initializer,\n",
    "                      name = 'encoder_layer_{}_1'.format(block_num))(inp)\n",
    "        conv = Conv2D(filters,\n",
    "                      kernel_size,\n",
    "                      strides = strides,\n",
    "                      activation = activation,\n",
    "                      padding = padding, \n",
    "                      kernel_initializer = kernel_initializer,\n",
    "                      name = 'encoder_layer_{}_2'.format(block_num))(conv)\n",
    "        if dropout_rate:\n",
    "            conv = Dropout(dropout_rate, name = 'enc_dropout_layer_{}'.format(block_num))(conv)\n",
    "        out = MaxPool2D(name = 'enc_maxpool_layer_{}'.format(block_num))(conv)\n",
    "        return conv, out\n",
    "\n",
    "    def decoderBlock(inp, \n",
    "                     filters,\n",
    "                     kernel_size,\n",
    "                     conv_block,\n",
    "                     block_num,\n",
    "                     strides = 1,\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same',\n",
    "                     kernel_initializer = 'he_normal',\n",
    "                     dropout_rate = None):\n",
    "\n",
    "        conv = Conv2DTranspose(filters, \n",
    "                               2, \n",
    "                               strides = 2,\n",
    "                               padding = padding, \n",
    "                               kernel_initializer = kernel_initializer,\n",
    "                               name = 'dec_layer_transpose_{}'.format(block_num))(inp)\n",
    "        conv = Concatenate(name = 'dec_concat_layer_{}'.format(block_num))([conv, conv_block])\n",
    "        conv = Conv2D(filters,\n",
    "                      kernel_size,\n",
    "                      activation = activation,\n",
    "                      padding = padding,\n",
    "                      strides = strides,\n",
    "                      kernel_initializer = kernel_initializer,\n",
    "                      name = 'decoder_layer_{}_1'.format(block_num))(conv)\n",
    "        conv = Conv2D(filters,\n",
    "                      kernel_size,\n",
    "                      activation = activation,\n",
    "                      padding = padding,\n",
    "                      strides = strides,\n",
    "                      kernel_initializer = kernel_initializer,\n",
    "                      name = 'decoder_layer_{}_2'.format(block_num))(conv)\n",
    "        if dropout_rate:\n",
    "            out = Dropout(dropout_rate, name = 'dec_dropout_layer_{}'.format(block_num))(conv)\n",
    "        return out\n",
    "\n",
    "\n",
    "    input_layer = Input(shape = input_shape, name = 'main_input_layer')\n",
    "\n",
    "    weight_map = Input(shape = input_shape[:2] + (n_classes,), name = 'weight_map_input_layer')\n",
    "\n",
    "    latent_layer_params = (filter_seq[-1], dropout_seq[-1])\n",
    "    filter_seq = filter_seq[:-1]\n",
    "    dropout_seq = dropout_seq[:-1]\n",
    "\n",
    "    # Adding encoder layers\n",
    "    encoder_blocks_outs = []\n",
    "    encoder_blocks_conv = []\n",
    "\n",
    "    for i, (num_filters, dropout_rate)  in enumerate(zip(filter_seq, dropout_seq)):\n",
    "        if i == 0:\n",
    "            encoder_conv, encoder_out = encoderBlock(input_layer,\n",
    "                                                     num_filters,\n",
    "                                                     kernel_size,\n",
    "                                                     i+1,\n",
    "                                                     activation = activation,\n",
    "                                                     padding = padding,\n",
    "                                                     kernel_initializer = kernel_initializer,\n",
    "                                                     dropout_rate = dropout_rate)\n",
    "        else:\n",
    "            encoder_conv, encoder_out = encoderBlock(encoder_blocks_outs[i-1],\n",
    "                                                     num_filters,\n",
    "                                                     kernel_size,\n",
    "                                                     i+1,\n",
    "                                                     activation = activation,\n",
    "                                                     padding = padding,\n",
    "                                                     kernel_initializer = kernel_initializer,\n",
    "                                                     dropout_rate = dropout_rate)\n",
    "        encoder_blocks_outs.append(encoder_out)\n",
    "        encoder_blocks_conv.append(encoder_conv)\n",
    "\n",
    "    # Adding latent layer\n",
    "    latent_layer = Conv2D(latent_layer_params[0], \n",
    "                          3, \n",
    "                          activation='relu', \n",
    "                          padding='same', \n",
    "                          kernel_initializer='he_normal',\n",
    "                          name = 'latent_layer_1')(encoder_blocks_outs[-1])\n",
    "    latent_layer = Conv2D(latent_layer_params[0],\n",
    "                          3, \n",
    "                          activation='relu', \n",
    "                          padding='same', \n",
    "                          kernel_initializer='he_normal',\n",
    "                          name = 'latent_layer_2')(latent_layer)\n",
    "    if latent_layer_params[1]:\n",
    "        latent_layer_out = Dropout(latent_layer_params[1], \n",
    "                                   name = 'latent_dropout_layer')(latent_layer)\n",
    "\n",
    "    decoder_blocks_outs = []\n",
    "\n",
    "    for i, (num_filters, dropout_rate)  in enumerate(zip(reversed(filter_seq), reversed(dropout_seq))):\n",
    "        if i == 0:\n",
    "            decoder_out = decoderBlock(latent_layer_out,\n",
    "                                       num_filters,\n",
    "                                       kernel_size,\n",
    "                                       encoder_blocks_conv[-1-i],\n",
    "                                       i+1,\n",
    "                                       activation = activation,\n",
    "                                       padding = padding,\n",
    "                                       kernel_initializer = kernel_initializer,\n",
    "                                       dropout_rate = dropout_rate)\n",
    "        else:\n",
    "            decoder_out = decoderBlock(decoder_blocks_outs[i-1],\n",
    "                                       num_filters,\n",
    "                                       kernel_size,\n",
    "                                       encoder_blocks_conv[-1-i],\n",
    "                                       i+1,\n",
    "                                       activation = activation,\n",
    "                                       padding = padding,\n",
    "                                       kernel_initializer = kernel_initializer,\n",
    "                                       dropout_rate = dropout_rate)\n",
    "        decoder_blocks_outs.append(decoder_out)\n",
    "\n",
    "\n",
    "    # Output softmax layer\n",
    "    softmax_out = Conv2D(n_classes, \n",
    "                         1, \n",
    "                         activation = activation, \n",
    "                         kernel_initializer = kernel_initializer,\n",
    "                         name = 'softmax_layer')(decoder_blocks_outs[-1])\n",
    "\n",
    "    # Adding custom categorical crossentropy loss - Non trainable layers\n",
    "    \n",
    "\n",
    "    # Final model\n",
    "    model = Model(inputs=[input_layer, weight_map], outputs=[softmax_out, weight_map])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwszUS1cHTFu"
   },
   "outputs": [],
   "source": [
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    smooth = 1e-12\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "epsilon = 0.2\n",
    "def custom_loss(target, output):\n",
    "    out = output[0]\n",
    "    wmap = output[1]\n",
    "    out =  out / tf.reduce_sum(out, len(out.get_shape()) - 1, True)\n",
    "    out = tf.clip_by_value(out, epsilon, 1. - epsilon)\n",
    "    out = tf.log(out)\n",
    "    weighted_output = tf.multiply(out, wmap)\n",
    "    -tf.reduce_sum(target * output, len(output.get_shape()) - 1)\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1e-12\n",
    "    flatten_y_true = K.flatten(y_true)\n",
    "    flatten_y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(flatten_y_true * flatten_y_pred)\n",
    "    union = K.sum(flatten_y_true) + K.sum(flatten_y_pred)\n",
    "    diceCoeff = 2 * (intersection + smooth) / (union + smooth)\n",
    "    return diceCoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fY5lshaTHTGA"
   },
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 20)\n",
    "n_classes = 1\n",
    "epsilon = 0\n",
    "model = getModel(input_shape, n_classes, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZ33M5z3HTGd"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss=custom_loss, metrics=[dice_coef, jaccard_coef_int, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNkG-EI_HTGu"
   },
   "outputs": [],
   "source": [
    "def get_normalized_patches():\n",
    "    data = np.load(processed_data_dir + '/data_pos_%d_%d_train_class%d.npy' % (Patch_size, N_split, class_type))\n",
    "    img = data[:,:,:,:20]\n",
    "    msk = data[:,:,:,20:21]\n",
    "    wmap = data[:, :, :, 21:]\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img = (img - mean)/std\n",
    "    return img, msk, wmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6UuZ1GXHTHB"
   },
   "outputs": [],
   "source": [
    "img, msk, wmap = get_normalized_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqC2pFNsHTHU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 859 samples, validate on 96 samples\n",
      "Epoch 1/100\n",
      "859/859 [==============================] - 53s 62ms/step - loss: 0.0000e+00 - dice_coef: 4.9851e-18 - jaccard_coef_int: 5.6420e-16 - accuracy: 0.8596 - val_loss: 0.0000e+00 - val_dice_coef: 3.5131e-18 - val_jaccard_coef_int: 3.9864e-16 - val_accuracy: 0.7164\n",
      "Epoch 2/100\n",
      "859/859 [==============================] - 24s 28ms/step - loss: 0.0000e+00 - dice_coef: 5.0123e-18 - jaccard_coef_int: 5.6949e-16 - accuracy: 0.8596 - val_loss: 0.0000e+00 - val_dice_coef: 3.5131e-18 - val_jaccard_coef_int: 3.9864e-16 - val_accuracy: 0.7164\n",
      "Epoch 3/100\n",
      "448/859 [==============>...............] - ETA: 10s - loss: 0.0000e+00 - dice_coef: 4.4565e-18 - jaccard_coef_int: 5.0306e-16 - accuracy: 0.8588"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-278e25a55a4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     callbacks=[model_checkpoint, early_stopping])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint('wmap_unet_c1_{epoch:02d}.hdf5')\n",
    "early_stopping = EarlyStopping(patience = 3)\n",
    "history = model.fit(x = [img, wmap],\n",
    "                    y = msk,\n",
    "                    epochs = 100,\n",
    "                    batch_size = 64,\n",
    "                    validation_split = 0.1,\n",
    "                    callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqID1lMaHTHl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input_layer (InputLayer)   (None, 224, 224, 20) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_1_1 (Conv2D)      (None, 224, 224, 32) 5792        main_input_layer[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_1_2 (Conv2D)      (None, 224, 224, 32) 9248        encoder_layer_1_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "enc_dropout_layer_1 (Dropout)   (None, 224, 224, 32) 0           encoder_layer_1_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "enc_maxpool_layer_1 (MaxPooling (None, 112, 112, 32) 0           enc_dropout_layer_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_2_1 (Conv2D)      (None, 112, 112, 64) 18496       enc_maxpool_layer_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_2_2 (Conv2D)      (None, 112, 112, 64) 36928       encoder_layer_2_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "enc_dropout_layer_2 (Dropout)   (None, 112, 112, 64) 0           encoder_layer_2_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "enc_maxpool_layer_2 (MaxPooling (None, 56, 56, 64)   0           enc_dropout_layer_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_3_1 (Conv2D)      (None, 56, 56, 128)  73856       enc_maxpool_layer_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_3_2 (Conv2D)      (None, 56, 56, 128)  147584      encoder_layer_3_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "enc_dropout_layer_3 (Dropout)   (None, 56, 56, 128)  0           encoder_layer_3_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "enc_maxpool_layer_3 (MaxPooling (None, 28, 28, 128)  0           enc_dropout_layer_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_4_1 (Conv2D)      (None, 28, 28, 256)  295168      enc_maxpool_layer_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_4_2 (Conv2D)      (None, 28, 28, 256)  590080      encoder_layer_4_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "enc_dropout_layer_4 (Dropout)   (None, 28, 28, 256)  0           encoder_layer_4_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "enc_maxpool_layer_4 (MaxPooling (None, 14, 14, 256)  0           enc_dropout_layer_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "latent_layer_1 (Conv2D)         (None, 14, 14, 512)  1180160     enc_maxpool_layer_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "latent_layer_2 (Conv2D)         (None, 14, 14, 512)  2359808     latent_layer_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "latent_dropout_layer (Dropout)  (None, 14, 14, 512)  0           latent_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dec_layer_transpose_1 (Conv2DTr (None, 28, 28, 256)  524544      latent_dropout_layer[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dec_concat_layer_1 (Concatenate (None, 28, 28, 512)  0           dec_layer_transpose_1[0][0]      \n",
      "                                                                 enc_dropout_layer_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_1_1 (Conv2D)      (None, 28, 28, 256)  1179904     dec_concat_layer_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_1_2 (Conv2D)      (None, 28, 28, 256)  590080      decoder_layer_1_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dec_dropout_layer_1 (Dropout)   (None, 28, 28, 256)  0           decoder_layer_1_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dec_layer_transpose_2 (Conv2DTr (None, 56, 56, 128)  131200      dec_dropout_layer_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dec_concat_layer_2 (Concatenate (None, 56, 56, 256)  0           dec_layer_transpose_2[0][0]      \n",
      "                                                                 enc_dropout_layer_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_2_1 (Conv2D)      (None, 56, 56, 128)  295040      dec_concat_layer_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_2_2 (Conv2D)      (None, 56, 56, 128)  147584      decoder_layer_2_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dec_dropout_layer_2 (Dropout)   (None, 56, 56, 128)  0           decoder_layer_2_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dec_layer_transpose_3 (Conv2DTr (None, 112, 112, 64) 32832       dec_dropout_layer_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dec_concat_layer_3 (Concatenate (None, 112, 112, 128 0           dec_layer_transpose_3[0][0]      \n",
      "                                                                 enc_dropout_layer_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_3_1 (Conv2D)      (None, 112, 112, 64) 73792       dec_concat_layer_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_3_2 (Conv2D)      (None, 112, 112, 64) 36928       decoder_layer_3_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dec_dropout_layer_3 (Dropout)   (None, 112, 112, 64) 0           decoder_layer_3_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dec_layer_transpose_4 (Conv2DTr (None, 224, 224, 32) 8224        dec_dropout_layer_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dec_concat_layer_4 (Concatenate (None, 224, 224, 64) 0           dec_layer_transpose_4[0][0]      \n",
      "                                                                 enc_dropout_layer_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_4_1 (Conv2D)      (None, 224, 224, 32) 18464       dec_concat_layer_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_4_2 (Conv2D)      (None, 224, 224, 32) 9248        decoder_layer_4_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dec_dropout_layer_4 (Dropout)   (None, 224, 224, 32) 0           decoder_layer_4_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "softmax_layer (Conv2D)          (None, 224, 224, 1)  33          dec_dropout_layer_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 224, 224, 1)  0           softmax_layer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 224, 224, 1)  0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 224, 224, 1)  0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "weight_map_input_layer (InputLa (None, 224, 224, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 224, 224, 1)  0           lambda_3[0][0]                   \n",
      "                                                                 weight_map_input_layer[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 7,764,993\n",
      "Trainable params: 7,764,993\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "image_segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
